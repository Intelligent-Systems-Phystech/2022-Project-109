\documentclass{article}
\usepackage{arxiv}

\usepackage[]{cite}
\usepackage{cmap}
\usepackage{amsmath, amsfonts,amssymb}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\newcommand\argmin{\mathop{\arg\min}}
\newcommand{\T}{^{\text{\tiny\sffamily\upshape\mdseries T}}}
\newcommand{\hchi}{\hat{\boldsymbol{\chi}}}
\newcommand{\hphi}{\hat{\boldsymbol{\varphi}}}
\newcommand{\bchi}{\boldsymbol{\chi}}
\newcommand{\A}{\mathbf{A}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\E}{\mathbf{E}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\hx}{\hat{x}}
\newcommand{\hX}{\hat{\X}}
\newcommand{\hy}{\hat{y}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\p}{p(\cdot)}
\newcommand{\cc}{\mathbf{c}}
\newcommand{\m}{\mathbf{m}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\e}{\mathbf{e}}
\newcommand{\h}{\mathbf{h}}
\newcommand{\q}{q(\cdot)}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\dd}{\partial}

\renewcommand{\baselinestretch}{1}
\renewcommand{\abstractname}{Аннотация}



\title{Непрерывное время при построении нейроинтерфейса BCI}

\author{ Змушко Филипп \\
	МФТИ \\
	\texttt{zmushko.fa@phystech.edu} \\
	%% examples of more authors
	\And
	Самохина Алина \\
	МФТИ\\
	\texttt{alina.samokhina@phystech.edu} \\
	%% examples of more authors
	\And
	Стрижов Вадим \\
	МФТИ\\
	\texttt{strijov@phystech.edu} \\
}
\date{}

\renewcommand{\shorttitle}{Непрерывное время при построении нейроинтерфейса}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
% \hypersetup{
% pdftitle={A template for the arxiv style},
% pdfsubject={q-bio.NC, q-bio.QM},
% pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
% pdfkeywords={First keyword, Second keyword, More},
% }

\begin{document}
\maketitle

\begin{abstract}
	В задачах декодирования сигнала непрерывный процесс исследуется с помощью рекуррентных нейронных сетей, использующих дискретное представление о времени. Недавно появившиеся модели, основывающиеся на нейронных обыкновенных дифференциальных уравнений рассматривают временные ряды как непрерывные во времени.
    В данной работе исследуется задача декодирования сигнала через представление в виде непрерывной во времени функции. Проводится сравнение базовых моделей, использующих дискретное время, с моделями на основе нейронных дифференциальных уравнений: обыкновенных и управляемых. Исследуется применение моделей на основе нейронных дифференциальных уравнений как для регулярных сигналов, так и для сигналов с пропущенными значениями. 
\end{abstract}



\section{Введение}
Данная статья посвящена  использованию непрерывного по времени сигнала при построении интерфейса мозг-компьютер (ИМК). ИМК~--- технология, позволяющая человеку взаимодействовать с компьютером посредством обработки данных об электрической активности мозга. Рассматривается задача декодирования сигнала электроэнцефалограмм (ЭЭГ). Основной сложностью при работе с сигналами ЭЭГ является нерегулярные по времени данные. Это происходит из-за того, что обычно устройства предназначены для массового употребления и имеют малое число датчиков и низкую частоту дискретизации сигнала. Для улучшения качества декодирования сигнала предлагается использовать модели на основе непрерывного представления сигнала во времени.

Один из подходов для получения непрерывного представления сигнала основывается на идее нейронных дифференциальных уравнений. Данная концепция, изложенная в \cite{NEURIPS2018_69386f6b}, рассматривает скрытое состояние ResNet как непрерывное во времени. Дальнейшее развитие этой идеи привело к появлению целого класса моделей, использующих непрерывное представление времени в рекуррентных нейронных сетях. В \cite{lechner2020longterm} рассматривается непрерывный аналог LSTM. Применение нейронных ОДУ к временным рядам с нерегулярным шагом по временной сетке представлено в \cite{cde}. В \cite{NEURIPS2019_952285b9} авторы рассматривают непрерывное представление во времени в виде разложения на полиномы Лежандра. 

В данной работе вышеперечисленные модели сравниваются на задаче декодирования сигнала. Изучены примененимость данных моделей для обработки нерегулярных во времени сигналов, получения непрерывного представления сигнала и построения нейроинтерфейса, работающего с непрерывным представлением о времени.

Модели на основе NODE, а также базовые моделей (RNN, EEGNet\cite{Lawhern2018EEGNetAC}, ERPCov TS LR\cite{6046114}), использующие дискретное представление времени, сравниваются в рамках декодирования сигнала на наборе данных потенциалов P300. Рассматриваемые здесь потенциалы P300~--- вызванные потенциалы, являющиеся специфическим откликом электрической активности мозга в ответ на внешний стимул.

Вышеперечисленные модели работают с непрерывным представлением временных рядов, но при этом не используют свойство непрерывности сигнала. В данной работе исследуется получение непрерывного представления сигнала, которое в дальнейшем может быть использовано при построении новых признаковых простанств. Эти представления могут рассматриваться как скрытые пространства, которые используются для согласовывания исходного сигнала с прогнозом с помощью корреляционного анализа.

\section{Постановка задачи}

\subsection{Задача классификации сигнала}
    
    Рассматривается задача классификации на выборке из регулярных по времени данных. Выборка делится на две части: обучающую и валидационную в соотношении 80:20.
    
    Выборка содержит $M$ (возможно, нерегулярных во времени) наблюдений. Тогда сигнал и целевая переменная определяются следующим образом:
    

    $$\X = \{\X_i\}_{i=1}^{M},$$
    $$\X_i = \{\x_t\}_{t\in T}, \ \x_t \in \R^E, \ T = \{t_i\}_{i=1}^{N},\ t_i \in \R$$ 
    
    $$\Y = \{y_i\}_{i=1}^{M},\ y_i \in \{0, 1\}$$
    
    $$E = 8 \text{~--- количество электродов},$$
    $$N = 40 \text{~--- количество наблюдений в одном отрезке ЭЭГ}.$$

    \paragraph{Постановка задачи классификации.}
    
    Решается задача бинарной классификации отрезков ЭЭГ. Требуется определить наличие в отрезке ЭЭГ потенциала P300.
    
    Для рассмотренных данных требуется получить целевую функцию:
    $$g_{\theta}: \X \to \Y.$$
    
    Критерием качества в данной задаче является бинарная кросс-энтропия: 
    $$L =  -{\frac {1}{M}}\sum _{m=1}^{M}\ {\bigg [}y_{m}\log {p}_{m}+(1-y_{m})\log(1-{p}_{m}){\bigg ]},$$
    $$p_m = g_{\theta}(\X_m) \text{ ~--- вероятность 1 класса для } \X_m.$$

    Решается оптимизационная задача:
    \begin{equation*}
    \hat{\theta} = \arg\max_{\theta} L(\theta, \X).
    \end{equation*}
    
    Внешними критериями качества для задачи классификации являются точность и F1-score.
    
\subsection{Построение непрерывного представления сигнала}\\
    
    Еще одной задачей данной работы является получение непрерывного представления сигнала. 
    Для наблюдаемого непрерывного процесса (активность мозга, движение):
    $$V(t), t \in \R.$$
    Задана выборка~--- реализация процесса $V(t)$:
    $$\X = \{\x_t\}_{t\in T},\  \x_t \in \R^E,\  T = \{t_i\}_{i=1}^{N}, t_i \in \R,$$ 
    $$\x_{t_i} \approx V(t_i).$$
    Предполагается, что можно получить:
    $$f_{\X}(t): \R \to \R^E, \ f_{\X}(t) = \x_t \approx V(t).$$

    В данной работе построение непрерывного представления рассматривается в рамках решения задачи классификации сигналов. Непрерывное представление извлекается из скрытых состояний рассматриваемых далее алгоритмов классификации.


\section{Вычислительный эксперимент}

\subsection{Цель эксперимента}

Сравнить результаты работы алгоритмов на основе NODE и алгоритмов, использующих дискретное представление времени. Провести данное сравнение как в случае регулярных сигналов, так и в случае данных с частично пропущенными значениями. Для моделей на основе NODE получить непрерывное во времени представление скрытого состояния.

\subsection{Экспериментальные данные}

\subsubsection{Набор данных P300}

Набор данных записывался с помощью энцефалографа NVX-52 (МКС, Зеленоград) с частотой 500 Гц. Для записи использовались 8 губчатых электродов (Cz, P3, P4, PO3, POz, PO4, O1, O2). Стимулы предъявлялись
с помощью шлема HTC Vive Pro VR.

Эксперимент был основан на игре в виртуальной реальности с нейроуправлением, основанным на класификации потенциала P300. Процесс игры заключался в кормлении енотов и защите их от демонов. В ходе обучения участникам указывался один из пяти енотов, на котором нужно было сконцентрироваться. Каждый акт игры состоял из случайных активаций различных енотов. В одном акте происходило по 10 активаций каждой цели, и для одного участника обучение состояло из 5 актов. Таким образом на выходе этапа обучения получалось 500 отрезков ЭЭГ для обучения классификатора: 50 целевых отрезков, содержащих потенциал P300 и 450 нецелевых.

На этапе обратной связи стимулами служили демоны. Участник должен был концентрироваться на выбранном демоне для уничтожения цели, которое происходило в конце акта.

Суммарное количество отрезков ЭЭГ в полученном наборе данных: 56540.

\subsubsection{Другой/ие датасет/ы?}

\subsection{Структура эксперимента}

Набор данных делился на обучающую и тестовую выборки в соотношении 80:20. Для эксперимента на данных с частично пропущенными значениями предварительно удалялись 20\% случайных точек. Для обучения использовался алгоритм оптимизации Adam. В качестве критерия оптимизации была взята кросс-энтропия. Сравнение результатов проводилось с помощью метрик точности и F1-score. 

\subsection{Результаты эксперимента}

(Появятся потом)


\section{Список графиков}

Зависимость качества (метрик) от количества параметров (размерности скрытых пространств) для всех моделей

Зависимость качества от количества пропущенных данных

Зависимость качества от количества эпох (?)





\bibliographystyle{plain}


\bibliography{Zmushko2022ContinuousTime}



\end{document}